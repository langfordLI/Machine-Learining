{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association analysis with Apriori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = loadDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createC1(dataSet):\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    return list(map(frozenset, C1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({1}),\n",
       " frozenset({2}),\n",
       " frozenset({3}),\n",
       " frozenset({4}),\n",
       " frozenset({5})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = createC1(dataSet)\n",
    "C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scanD(D, Ck, minSupport):\n",
    "    \"\"\"\n",
    "    D: dataSet\n",
    "    Ck: candidate items\n",
    "    \"\"\"\n",
    "    ssCnt = {}\n",
    "    for tid in D:\n",
    "        for can in Ck:\n",
    "            if can.issubset(tid):\n",
    "                if not can in ssCnt:\n",
    "                    ssCnt[can] = 1\n",
    "                else:\n",
    "                    ssCnt[can] += 1\n",
    "    numItems = float(len(D))\n",
    "    reList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key] / numItems\n",
    "        if support >= minSupport:\n",
    "            reList.insert(0, key)\n",
    "        supportData[key] = support\n",
    "    return reList, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = map(set, dataSet)\n",
    "L1, supportData0 = scanD(dataSet, C1, 0.5)\n",
    "L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aprioriGen(Lk, k):\n",
    "    \"\"\"\n",
    "    Lk: a list of frequent itemsets( such as {0, 1} {0, 2} {0, 3} {1, 2} {1, 3} {2, 3}...  )\n",
    "    k: the size of the itemsets (such as going to merge front set into three dimension {0, 1, 2, 3}...)\n",
    "    \"\"\"\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk): # get random set to merge in one set\n",
    "            L1 = list(Lk[i])[: k - 2] # if you want to construct three from two, compare only the k - 2 (one) element\n",
    "            L2 = list(Lk[j])[: k - 2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            if L1 == L2:\n",
    "                retList.append(Lk[i] | Lk[j]) # merge set use |(and)\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(dataSet, minSupport = 0.5): # generate a list of candidate itemsets\n",
    "    C1 = createC1(dataSet) # use createC1() function get simple set item\n",
    "    D = list(map(set, dataSet)) # list(map()) turn the dataSet into list of map\n",
    "    L1, supportData = scanD(D, C1, minSupport) # scan out support less set\n",
    "    L = [L1] # add L1 into a larger list\n",
    "    k = 2\n",
    "    while(len(L[k - 2]) > 0): # L[k - 2] express number of k-1 dimension set\n",
    "        Ck = aprioriGen(L[k - 2], k) # to create k dimension set search L[k - 2](which number of k-1 dimension)\n",
    "        Lk, supK = scanD(D, Ck, minSupport) # decrease support low set\n",
    "        supportData.update(supK) # dict.update(dict2) 字典update()函数把字典dict2的键/值对更新到dict里\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({1}): 0.5,\n",
       " frozenset({3}): 0.75,\n",
       " frozenset({4}): 0.25,\n",
       " frozenset({2}): 0.75,\n",
       " frozenset({5}): 0.75,\n",
       " frozenset({1, 3}): 0.5,\n",
       " frozenset({2, 5}): 0.75,\n",
       " frozenset({3, 5}): 0.5,\n",
       " frozenset({2, 3}): 0.5,\n",
       " frozenset({1, 5}): 0.25,\n",
       " frozenset({1, 2}): 0.25,\n",
       " frozenset({2, 3, 5}): 0.5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L, supportData = apriori(dataSet)\n",
    "supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRules(L, supportData, minConf = 0.7):\n",
    "    \"\"\"\n",
    "    L: same as before dictionary [[{one-dimension}, ...], [{two-dimension}, ...], [{three-dimension}, ...]]\n",
    "    supportData: support data in dictionary\n",
    "    {0, 1} if there is rules as 0->1\n",
    "    \"\"\"\n",
    "    bigRuleList = [] # save all rules with all confidence values\n",
    "    for i in range(1, len(L)): # for signal item there is no rules of association\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet] # create a list of single-item sets [{0}, {1}, {2}] or [{0, 1}, {0, 2}..]\n",
    "            if(i > 1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf) # if single-item larger than 2 think to merge\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf) # for two dimension set\n",
    "    return bigRuleList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcConf(freqSet, H, supportData, brl, minConf = 0.7):\n",
    "    \"\"\"\n",
    "    freqSet: [{0, 1}, {0, 2}, {1, 2}....]\n",
    "    H: [frozenSet(0), frozenSet(1), frozenSet(2),... ] which all of them is frozenSet\n",
    "    supportData: save all support data for those itemsets\n",
    "    brl: big regular set\n",
    "    \"\"\"\n",
    "    prunedH = []\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet] / supportData[freqSet - conseq]\n",
    "        if conf >= minConf:\n",
    "            print(freqSet - conseq, '-->', conseq, 'conf', conf)\n",
    "            brl.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq) # pass rule then save \n",
    "    return prunedH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf = 0.7):\n",
    "    \"\"\"\n",
    "    freqSet: [{0, 1, 2}, {0, 2, 3}, {1, 2, 3}.../{0, 1, 3, 4}, {1, 2, 3, 5}, .../...]\n",
    "    H: [frozenSet(0), frozenSet(1), frozenSet(2),... ] which all of them is frozenSet which will on the right-hand side of a rule\n",
    "    supportData: save all support data for those itemsets\n",
    "    brl: big regular set\n",
    "    \"\"\"\n",
    "    m = len(H[0])\n",
    "    print(freqSet)\n",
    "    print(H)\n",
    "    if (len(freqSet) > (m + 1)): # 频繁项集元素数目大于单个集合的元素数\n",
    "        Hmp1 = aprioriGen(H, m + 1)# 存在不同顺序、元素相同的集合，合并具有相同部分的集合\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n",
    "        if len(Hmp1) > 1:\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({5}) --> frozenset({2}) conf 1.0\n",
      "frozenset({2}) --> frozenset({5}) conf 1.0\n",
      "frozenset({1}) --> frozenset({3}) conf 1.0\n",
      "frozenset({2, 3, 5})\n",
      "[frozenset({2}), frozenset({3}), frozenset({5})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({1}), frozenset({3}), 1.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateRules(L, supportData, minConf = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
